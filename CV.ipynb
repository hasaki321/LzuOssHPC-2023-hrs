{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e220241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import list_models,get_model\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model import GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525c3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasaki\\miniconda3\\envs\\DL\\lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "googlenet = get_model(\"googlenet\", weights=None)\n",
    "resnet = get_model(\"resnet50\", weights=None)\n",
    "vgg = get_model(\"vgg11\", weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f3302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg = get_model(\"vgg11\")\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(1000,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,100)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.vgg(x)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de3507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_tfm = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_set = CIFAR100(root='./', train = True, download= True,transform=train_tfm)\n",
    "test_set = CIFAR100(root='./', train = False, download= True,transform=test_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9ffb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_config = {\n",
    "    \"lr\":1e-4,\n",
    "    \"weight_decay\":1e-4,\n",
    "}\n",
    "google_config = {\n",
    "    \"lr\":1e-4,\n",
    "    \"weight_decay\":1e-4,\n",
    "}\n",
    "vgg_config = {\n",
    "    \"model\":GoogLeNet(num_classes=100, aux_logits=True, init_weights=True),\n",
    "    \"lr\":0.0003,\n",
    "    \"weight_decay\":0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35ac308",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epoch = 5\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config = vgg_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48c35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images,target = list(zip(*batch))\n",
    "    target = nn.functional.one_hot(torch.tensor(target), num_classes=100).to(torch.float32)\n",
    "    images = torch.stack(images)\n",
    "    return images,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf06b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=config['model'].parameters(),lr=config['lr'],weight_decay=config['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5636716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch,model,loss_fn,optimizer):\n",
    "    global device\n",
    "    images,target = batch\n",
    "    images=images.to(device)\n",
    "    target=target.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     output = model(images)\n",
    "#     print(torch.softmax(output,-1))\n",
    "#     print(target)\n",
    "    output, aux_logits2, aux_logits1 = model(images)\n",
    "    loss0 = loss_fn(output, target)\n",
    "    loss1 = loss_fn(aux_logits1, target)\n",
    "    loss2 = loss_fn(aux_logits2, target)\n",
    "    loss = loss0 + loss1 * 0.3 + loss2 * 0.3\n",
    "\n",
    "#     loss = loss_fn(output,target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    acc = (output.argmax(dim=-1) == target).float().mean()\n",
    "#     acc = torch.sum(torch.argmax(torch.softmax(output,-1),dim=-1) == torch.argmax(target,dim=-1))/len(target)\n",
    "#     print(torch.argmax(torch.softmax(output,-1),dim=-1) , torch.argmax(target,dim=-1))\n",
    "    \n",
    "    return loss.item(), acc.item()\n",
    "\n",
    "\n",
    "def train_epoch(train_loader,model,loss_fn,optimizer,epoch):\n",
    "    show_bar = tqdm(train_loader)\n",
    "    show_bar.set_description(f'[Training Epoch: {epoch+1}]')\n",
    "    acc_recoder = []\n",
    "    loss_recoder = []\n",
    "    for idx,batch in enumerate(show_bar):\n",
    "        loss,acc = train_step(batch,model,loss_fn,optimizer)\n",
    "        loss_recoder.append(loss)\n",
    "        acc_recoder.append(acc)\n",
    "        \n",
    "        if (idx+1)%5==0:\n",
    "#             break\n",
    "            show_bar.set_postfix({'loss':f'{loss:.5f}','acc':f'{acc:.4f}'})\n",
    "    return loss_recoder,acc_recoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df7917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258692ac845c4dc0a542f48f04bbb85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=6.629838353837543 ,acc=0.06613650895140664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7717636d6774f61b7699ed94d2f228f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=6.043308506231479 ,acc=0.11391064578005115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc172d9731a24969a7b84880b89a4c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=5.784091513480067 ,acc=0.14426150895140666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf935cc5f44467cb816009e3f4929fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_loss = []\n",
    "total_acc = []\n",
    "model = config['model']\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    loss_recoder,acc_recoder = train_epoch(train_loader,model,loss_fn,optimizer,epoch)\n",
    "    print(f\"Epoch {epoch+1}: loss={sum(loss_recoder)/len(loss_recoder)} ,acc={sum(acc_recoder)/len(acc_recoder)}\")\n",
    "    total_loss+=loss_recoder\n",
    "    total_acc+=total_acc\n",
    "\n",
    "plt.plot(total_loss,\"b\")\n",
    "plt.show()\n",
    "plt.plot(total_acc,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38661cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
